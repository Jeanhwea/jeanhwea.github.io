<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2020-11-01 Sun 10:50 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>PyTorch</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Jinghui Hu" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="styles/readtheorg/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="styles/readtheorg/css/readtheorg.css"/>
<script type="text/javascript" src="styles/lib/js/jquery.min.js"></script>
<script type="text/javascript" src="styles/lib/js/bootstrap.min.js"></script>
<script type="text/javascript" src="styles/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript" src="styles/readtheorg/js/readtheorg.js"></script>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2019 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
</head>
<body>
<div id="org-div-home-and-up">
 <a accesskey="h" href="../readme.html"> UP </a>
 |
 <a accesskey="H" href="../index.html"> HOME </a>
</div><div id="content">
<h1 class="title">PyTorch</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgd4aad3f">1. PyTorch</a></li>
<li><a href="#orgb338fd3">2. 基础运算</a>
<ul>
<li><a href="#orgc947528">2.1. 初始化、数据类型</a></li>
<li><a href="#org78c50f5">2.2. 获取形状</a></li>
<li><a href="#orgd0a59ac">2.3. Tensor 和 ndarray 数据类型互转</a></li>
</ul>
</li>
<li><a href="#org13a9f3a">3. 形状变换</a>
<ul>
<li><a href="#org9fe92c9">3.1. 变形</a></li>
<li><a href="#orga5854f9">3.2. 拼接</a></li>
</ul>
</li>
<li><a href="#orgb4fc84a">4. CUDA 技术</a></li>
<li><a href="#orgdcea205">5. 定义模型</a>
<ul>
<li><a href="#org1f9e6c0">5.1. 实验代码</a></li>
</ul>
</li>
<li><a href="#orgff233a4">6. 附录</a></li>
<li><a href="#orgade9926">7. 参考链接</a></li>
</ul>
</div>
</div>


<div id="outline-container-orgd4aad3f" class="outline-2">
<h2 id="orgd4aad3f"><span class="section-number-2">1</span> PyTorch</h2>
<div class="outline-text-2" id="text-1">
<p>
PyTorch 和 Numpy 的数组和相似，PyTorch 的数据类型大多数是叫 Tensor，并且 Tensor
可以在 GPU 上进行计算，用于提高计算效率
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #b9ca4a;">import</span> torch
<span style="color: #b9ca4a;">import</span> torch.nn <span style="color: #b9ca4a;">as</span> nn
<span style="color: #b9ca4a;">import</span> torch.nn.functional <span style="color: #b9ca4a;">as</span> F

<span style="color: #b9ca4a;">import</span> torchvision
<span style="color: #b9ca4a;">import</span> torchvision.transforms <span style="color: #b9ca4a;">as</span> transforms

<span style="color: #b9ca4a;">import</span> numpy <span style="color: #b9ca4a;">as</span> np

torch.set_printoptions<span style="color: #8d5649;">(</span>linewidth=200<span style="color: #8d5649;">)</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-orgb338fd3" class="outline-2">
<h2 id="orgb338fd3"><span class="section-number-2">2</span> 基础运算</h2>
<div class="outline-text-2" id="text-2">
</div>
<div id="outline-container-orgc947528" class="outline-3">
<h3 id="orgc947528"><span class="section-number-3">2.1</span> 初始化、数据类型</h3>
<div class="outline-text-3" id="text-2-1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #e7c547;">x0</span> = torch.zeros<span style="color: #8d5649;">(</span>2, 3<span style="color: #8d5649;">)</span>
<span style="color: #e7c547;">x1</span> = torch.ones<span style="color: #8d5649;">(</span>3, 2<span style="color: #8d5649;">)</span>
<span style="color: #e7c547;">x2</span> = torch.zeros<span style="color: #8d5649;">(</span>2, 3, dtype=torch.<span style="color: #c397d8;">long</span><span style="color: #8d5649;">)</span> <span style="color: #969896; font-style: italic;"># </span><span style="color: #969896; font-style: italic;">dtype: int32 int64 float32 float64</span>
<span style="color: #e7c547;">x3</span> = torch.tensor<span style="color: #8d5649;">(</span><span style="color: #d8241f;">[</span>1.1, 3.0<span style="color: #d8241f;">]</span><span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>x1<span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>x2<span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>x3<span style="color: #8d5649;">)</span>
</pre>
</div>

<pre class="example">
tensor([[1., 1.],
        [1., 1.],
        [1., 1.]])
tensor([[0, 0, 0],
        [0, 0, 0]])
tensor([1.1000, 3.0000])

</pre>

<p>
获取默认创建的数据类型
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>torch.get_default_dtype<span style="color: #d8241f;">()</span><span style="color: #8d5649;">)</span>
</pre>
</div>

<pre class="example">
torch.float32

</pre>
</div>
</div>

<div id="outline-container-org78c50f5" class="outline-3">
<h3 id="org78c50f5"><span class="section-number-3">2.2</span> 获取形状</h3>
<div class="outline-text-3" id="text-2-2">
<p>
获取 Tensor 的形状和元素数量
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #e7c547;">x1</span> = torch.tensor<span style="color: #8d5649;">(</span><span style="color: #d8241f;">[</span>1.1, 3.0<span style="color: #d8241f;">]</span><span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>x1.size<span style="color: #d8241f;">()</span><span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>x1.numel<span style="color: #d8241f;">()</span><span style="color: #8d5649;">)</span> <span style="color: #969896; font-style: italic;"># </span><span style="color: #969896; font-style: italic;">number of elements</span>

<span style="color: #e7c547;">x2</span> = torch.tensor<span style="color: #8d5649;">(</span><span style="color: #d8241f;">[</span><span style="color: #9564bf;">[</span>1.1, 3.0, 3.3<span style="color: #9564bf;">]</span>, <span style="color: #9564bf;">[</span>3, 4, 5<span style="color: #9564bf;">]</span><span style="color: #d8241f;">]</span><span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>x2.size<span style="color: #d8241f;">()</span><span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>x2.numel<span style="color: #d8241f;">()</span><span style="color: #8d5649;">)</span>
</pre>
</div>

<pre class="example">
torch.Size([2])
2
torch.Size([2, 3])
6

</pre>
</div>
</div>

<div id="outline-container-orgd0a59ac" class="outline-3">
<h3 id="orgd0a59ac"><span class="section-number-3">2.3</span> Tensor 和 ndarray 数据类型互转</h3>
<div class="outline-text-3" id="text-2-3">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #e7c547;">t1</span> = torch.randn<span style="color: #8d5649;">(</span><span style="color: #d8241f;">(</span>2, 3<span style="color: #d8241f;">)</span><span style="color: #8d5649;">)</span> <span style="color: #969896; font-style: italic;"># </span><span style="color: #969896; font-style: italic;">normal distribution with shape (2,3)</span>
<span style="color: #e7c547;">a1</span> = t1.numpy<span style="color: #8d5649;">()</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>t1<span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>a1<span style="color: #8d5649;">)</span>

<span style="color: #e7c547;">a2</span> = np.random.normal<span style="color: #8d5649;">(</span>0, 0.01, 6<span style="color: #8d5649;">)</span>
<span style="color: #e7c547;">t2</span> = torch.from_numpy<span style="color: #8d5649;">(</span>a2<span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>a2<span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>t2<span style="color: #8d5649;">)</span>
</pre>
</div>

<pre class="example">
tensor([[-0.0652, -0.3537,  1.3550],
        [-0.6979, -0.7713, -0.5261]])
[[-0.0652356  -0.35367048  1.3549587 ]
 [-0.6978578  -0.7712709  -0.5261264 ]]
[-0.0092347  -0.00012146 -0.00581832 -0.00620685 -0.00119326 -0.00189925]
tensor([-0.0092, -0.0001, -0.0058, -0.0062, -0.0012, -0.0019], dtype=torch.float64)

</pre>

<p>
PyTorch 和 Numpy 数据关系包含两种关系：share vs. copy
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #e7c547;">a</span> = np.array<span style="color: #8d5649;">(</span><span style="color: #d8241f;">[</span>1, 2, 3<span style="color: #d8241f;">]</span><span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>a<span style="color: #8d5649;">)</span>

<span style="color: #e7c547;">t1</span> = torch.Tensor<span style="color: #8d5649;">(</span>a<span style="color: #8d5649;">)</span>
<span style="color: #e7c547;">t2</span> = torch.tensor<span style="color: #8d5649;">(</span>a<span style="color: #8d5649;">)</span>
<span style="color: #e7c547;">t3</span> = torch.as_tensor<span style="color: #8d5649;">(</span>a<span style="color: #8d5649;">)</span>
<span style="color: #e7c547;">t4</span> = torch.from_numpy<span style="color: #8d5649;">(</span>a<span style="color: #8d5649;">)</span>

<span style="color: #e7c547;">a</span><span style="color: #8d5649;">[</span>0<span style="color: #8d5649;">]</span> = 0
<span style="color: #e7c547;">a</span><span style="color: #8d5649;">[</span>1<span style="color: #8d5649;">]</span> = 0
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>t1<span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>t2<span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>t3<span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>t4<span style="color: #8d5649;">)</span>
</pre>
</div>

<pre class="example">
[1 2 3]
tensor([1., 2., 3.])
tensor([1, 2, 3])
tensor([0, 0, 3])
tensor([0, 0, 3])

</pre>
</div>
</div>
</div>

<div id="outline-container-org13a9f3a" class="outline-2">
<h2 id="org13a9f3a"><span class="section-number-2">3</span> 形状变换</h2>
<div class="outline-text-2" id="text-3">
</div>
<div id="outline-container-org9fe92c9" class="outline-3">
<h3 id="org9fe92c9"><span class="section-number-3">3.1</span> 变形</h3>
<div class="outline-text-3" id="text-3-1">
<p>
如果想要 resize 或 reshape 一个 tensor，可以使用 view 方法。如果需要 copy，用
clone, 如果需要源数据，用 view, reshape 这玩意不好控制，则没那么可控，他的执
行结果可能是源数据的一个 copy，也可能不是，最好少用
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #e7c547;">x1</span> = torch.randn<span style="color: #8d5649;">(</span>24<span style="color: #8d5649;">)</span>
<span style="color: #e7c547;">x2</span> = x1.view<span style="color: #8d5649;">(</span>2, 3, 4<span style="color: #8d5649;">)</span>
<span style="color: #e7c547;">x3</span> = x1.view<span style="color: #8d5649;">(</span>4, -1<span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>x2<span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>x3<span style="color: #8d5649;">)</span>
</pre>
</div>

<pre class="example">
tensor([[[-0.0513,  1.5727,  1.4737,  0.3913],
         [ 2.2639,  0.4963,  0.3401, -0.2731],
         [-1.4023,  1.7182,  0.9297,  0.1243]],

        [[-0.4909, -0.5568,  1.9808,  0.7490],
         [ 0.1885,  0.4245,  0.0027, -0.8911],
         [-0.7410,  1.0522, -0.8816, -2.5483]]])
tensor([[-0.0513,  1.5727,  1.4737,  0.3913,  2.2639,  0.4963],
        [ 0.3401, -0.2731, -1.4023,  1.7182,  0.9297,  0.1243],
        [-0.4909, -0.5568,  1.9808,  0.7490,  0.1885,  0.4245],
        [ 0.0027, -0.8911, -0.7410,  1.0522, -0.8816, -2.5483]])
</pre>

<p>
如果 tensor 里只有一个数字，item 方法可以把里面的 value 变成 Python 数值
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #e7c547;">x</span> = torch.randn<span style="color: #8d5649;">(</span>1<span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>x<span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>x.item<span style="color: #d8241f;">()</span><span style="color: #8d5649;">)</span>
</pre>
</div>

<pre class="example">
tensor([-0.4755])
-0.47550874948501587

</pre>

<p>
修改矩阵的形状，转置，交换维度等操作
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #e7c547;">x</span> = torch.arange<span style="color: #8d5649;">(</span>12<span style="color: #8d5649;">)</span>.view<span style="color: #8d5649;">(</span>2, 3, 2<span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>x<span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>x.transpose<span style="color: #d8241f;">(</span>1, 0<span style="color: #d8241f;">)</span><span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>x.permute<span style="color: #d8241f;">(</span>1, 0, 2<span style="color: #d8241f;">)</span><span style="color: #8d5649;">)</span>
</pre>
</div>

<pre class="example">
tensor([[[ 0,  1],
         [ 2,  3],
         [ 4,  5]],

        [[ 6,  7],
         [ 8,  9],
         [10, 11]]])
tensor([[[ 0,  1],
         [ 6,  7]],

        [[ 2,  3],
         [ 8,  9]],

        [[ 4,  5],
         [10, 11]]])
tensor([[[ 0,  1],
         [ 6,  7]],

        [[ 2,  3],
         [ 8,  9]],

        [[ 4,  5],
         [10, 11]]])
</pre>

<p>
压扁给定的维度为 1  的维度值
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #e7c547;">x</span> = torch.arange<span style="color: #8d5649;">(</span>6<span style="color: #8d5649;">)</span>.view<span style="color: #8d5649;">(</span>1, -1<span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>x.shape<span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>x<span style="color: #8d5649;">)</span>
<span style="color: #e7c547;">a1</span> = x.squeeze<span style="color: #8d5649;">(</span>0<span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>a1.shape<span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>a1<span style="color: #8d5649;">)</span>
<span style="color: #e7c547;">a2</span> = a1.unsqueeze<span style="color: #8d5649;">(</span>0<span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>a2<span style="color: #8d5649;">)</span>
</pre>
</div>

<pre class="example">
torch.Size([1, 6])
tensor([[0, 1, 2, 3, 4, 5]])
torch.Size([6])
tensor([0, 1, 2, 3, 4, 5])
tensor([[0, 1, 2, 3, 4, 5]])

</pre>

<p>
定义一个 flatten 函数，将输入数据扁平化
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #b9ca4a;">def</span> <span style="color: #e78c45;">flatten</span><span style="color: #8d5649;">(</span>t<span style="color: #8d5649;">)</span>:
    <span style="color: #e7c547;">t</span> = t.view<span style="color: #8d5649;">(</span>1, -1<span style="color: #8d5649;">)</span>
    <span style="color: #e7c547;">t</span> = t.squeeze<span style="color: #8d5649;">()</span>
    <span style="color: #b9ca4a;">return</span> t

<span style="color: #e7c547;">x1</span> = torch.tensor<span style="color: #8d5649;">(</span><span style="color: #d8241f;">[</span>1, 2, 3, 4, 5, 6<span style="color: #d8241f;">]</span>, dtype=torch.float32<span style="color: #8d5649;">)</span>.reshape<span style="color: #8d5649;">(</span>2, 3<span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>x1<span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>flatten<span style="color: #d8241f;">(</span>x1<span style="color: #d8241f;">)</span><span style="color: #8d5649;">)</span>
</pre>
</div>

<pre class="example">
tensor([[1., 2., 3.],
        [4., 5., 6.]])
tensor([1., 2., 3., 4., 5., 6.])

</pre>
</div>
</div>

<div id="outline-container-orga5854f9" class="outline-3">
<h3 id="orga5854f9"><span class="section-number-3">3.2</span> 拼接</h3>
<div class="outline-text-3" id="text-3-2">
<p>
将多个张量合并拼接成一个向量
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #e7c547;">t1</span> = torch.tensor<span style="color: #8d5649;">(</span><span style="color: #d8241f;">[</span><span style="color: #9564bf;">[</span>1, 2<span style="color: #9564bf;">]</span>, <span style="color: #9564bf;">[</span>3, 4<span style="color: #9564bf;">]</span><span style="color: #d8241f;">]</span><span style="color: #8d5649;">)</span>
<span style="color: #e7c547;">t2</span> = torch.tensor<span style="color: #8d5649;">(</span><span style="color: #d8241f;">[</span><span style="color: #9564bf;">[</span>5, 6<span style="color: #9564bf;">]</span>, <span style="color: #9564bf;">[</span>7, 8<span style="color: #9564bf;">]</span><span style="color: #d8241f;">]</span><span style="color: #8d5649;">)</span>

<span style="color: #e7c547;">x1</span> = torch.cat<span style="color: #8d5649;">(</span><span style="color: #d8241f;">(</span>t1, t2<span style="color: #d8241f;">)</span>, dim=0<span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>x1<span style="color: #8d5649;">)</span>
<span style="color: #e7c547;">x2</span> = torch.cat<span style="color: #8d5649;">(</span><span style="color: #d8241f;">(</span>t1, t2<span style="color: #d8241f;">)</span>, dim=1<span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>x2<span style="color: #8d5649;">)</span>
</pre>
</div>

<pre class="example">
tensor([[1, 2],
        [3, 4],
        [5, 6],
        [7, 8]])
tensor([[1, 2, 5, 6],
        [3, 4, 7, 8]])

</pre>
</div>
</div>
</div>

<div id="outline-container-orgb4fc84a" class="outline-2">
<h2 id="orgb4fc84a"><span class="section-number-2">4</span> CUDA 技术</h2>
<div class="outline-text-2" id="text-4">
<p>
Tensor 可以放在 CUDA 显卡上进行计算
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #e7c547;">x</span> = torch.randn<span style="color: #8d5649;">(</span>2, 3<span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">if</span> torch.cuda.is_available<span style="color: #8d5649;">()</span>:
    <span style="color: #e7c547;">device</span> = torch.device<span style="color: #8d5649;">(</span><span style="color: #70c0b1;">"cuda:0"</span><span style="color: #8d5649;">)</span>  <span style="color: #969896; font-style: italic;"># </span><span style="color: #969896; font-style: italic;">a CUDA device object</span>
    <span style="color: #e7c547;">y</span> = torch.ones_like<span style="color: #8d5649;">(</span>x, device=device<span style="color: #8d5649;">)</span>  <span style="color: #969896; font-style: italic;"># </span><span style="color: #969896; font-style: italic;">directly create a tensor on GPU</span>
    <span style="color: #e7c547;">x</span> = x.to<span style="color: #8d5649;">(</span>device<span style="color: #8d5649;">)</span>  <span style="color: #969896; font-style: italic;"># </span><span style="color: #969896; font-style: italic;">or just use strings ``.to("cuda")``</span>
    <span style="color: #e7c547;">z</span> = x + y
    <span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>z<span style="color: #8d5649;">)</span>
    <span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>z.to<span style="color: #d8241f;">(</span><span style="color: #70c0b1;">"cpu"</span>, torch.double<span style="color: #d8241f;">)</span><span style="color: #8d5649;">)</span>  <span style="color: #969896; font-style: italic;"># </span><span style="color: #969896; font-style: italic;">``.to`` can also change dtype together!</span>
<span style="color: #b9ca4a;">else</span>:
    <span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span><span style="color: #70c0b1;">"gpu is not available"</span><span style="color: #8d5649;">)</span>
</pre>
</div>

<pre class="example">
gpu is not available

</pre>
</div>
</div>

<div id="outline-container-orgdcea205" class="outline-2">
<h2 id="orgdcea205"><span class="section-number-2">5</span> 定义模型</h2>
<div class="outline-text-2" id="text-5">
<p>
PyTorch 构造模型时主要包含两个步骤：
</p>
<ol class="org-ol">
<li>继承 <code>nn.Module</code> 类</li>
<li>实现 <code>forward()</code> 方法</li>
</ol>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #b9ca4a;">import</span> torch
<span style="color: #b9ca4a;">import</span> torch.nn <span style="color: #b9ca4a;">as</span> nn


<span style="color: #b9ca4a;">class</span> <span style="color: #7aa6da;">Network</span><span style="color: #8d5649;">(</span>nn.Module<span style="color: #8d5649;">)</span>:
    <span style="color: #b9ca4a;">def</span> <span style="color: #e78c45;">__init__</span><span style="color: #8d5649;">(</span><span style="color: #b9ca4a;">self</span><span style="color: #8d5649;">)</span>:
        <span style="color: #c397d8;">super</span><span style="color: #8d5649;">(</span>Network, <span style="color: #b9ca4a;">self</span><span style="color: #8d5649;">)</span>.__init__<span style="color: #8d5649;">()</span>

    <span style="color: #b9ca4a;">def</span> <span style="color: #e78c45;">forward</span><span style="color: #8d5649;">(</span><span style="color: #b9ca4a;">self</span>, in_data<span style="color: #8d5649;">)</span>:
        <span style="color: #e7c547;">out_data</span> = in_data
        <span style="color: #b9ca4a;">return</span> out_data
</pre>
</div>
</div>

<div id="outline-container-org1f9e6c0" class="outline-3">
<h3 id="org1f9e6c0"><span class="section-number-3">5.1</span> 实验代码</h3>
<div class="outline-text-3" id="text-5-1">
<p>
完整的定义网络模型的代码参考如下代码
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #b9ca4a;">import</span> torch
<span style="color: #b9ca4a;">import</span> torch.nn <span style="color: #b9ca4a;">as</span> nn
<span style="color: #b9ca4a;">import</span> torch.nn.functional <span style="color: #b9ca4a;">as</span> F

<span style="color: #b9ca4a;">import</span> torchvision
<span style="color: #b9ca4a;">import</span> torchvision.transforms <span style="color: #b9ca4a;">as</span> transforms

torch.set_printoptions<span style="color: #8d5649;">(</span>linewidth=200<span style="color: #8d5649;">)</span>

<span style="color: #b9ca4a;">class</span> <span style="color: #7aa6da;">Network</span><span style="color: #8d5649;">(</span>nn.Module<span style="color: #8d5649;">)</span>:
  <span style="color: #b9ca4a;">def</span> <span style="color: #e78c45;">__init__</span><span style="color: #8d5649;">(</span><span style="color: #b9ca4a;">self</span><span style="color: #8d5649;">)</span>:
    <span style="color: #c397d8;">super</span><span style="color: #8d5649;">()</span>.__init__<span style="color: #8d5649;">()</span>
    <span style="color: #b9ca4a;">self</span>.conv1 = nn.Conv2d<span style="color: #8d5649;">(</span>in_channels=1, out_channels=6, kernel_size=5<span style="color: #8d5649;">)</span>
    <span style="color: #b9ca4a;">self</span>.conv2 = nn.Conv2d<span style="color: #8d5649;">(</span>in_channels=6, out_channels=12, kernel_size=5<span style="color: #8d5649;">)</span>

    <span style="color: #b9ca4a;">self</span>.fc1 = nn.Linear<span style="color: #8d5649;">(</span>in_features=12 * 4 * 4, out_features=120<span style="color: #8d5649;">)</span>
    <span style="color: #b9ca4a;">self</span>.fc2 = nn.Linear<span style="color: #8d5649;">(</span>in_features=120, out_features=60<span style="color: #8d5649;">)</span>
    <span style="color: #b9ca4a;">self</span>.out = nn.Linear<span style="color: #8d5649;">(</span>in_features=60, out_features=10<span style="color: #8d5649;">)</span>

  <span style="color: #b9ca4a;">def</span> <span style="color: #e78c45;">forward</span><span style="color: #8d5649;">(</span><span style="color: #b9ca4a;">self</span>, t<span style="color: #8d5649;">)</span>:
    <span style="color: #e7c547;">t</span> = F.relu<span style="color: #8d5649;">(</span><span style="color: #b9ca4a;">self</span>.conv1<span style="color: #d8241f;">(</span>t<span style="color: #d8241f;">)</span><span style="color: #8d5649;">)</span>
    <span style="color: #e7c547;">t</span> = F.max_pool2d<span style="color: #8d5649;">(</span>t, kernel_size=2, stride=2<span style="color: #8d5649;">)</span>

    <span style="color: #e7c547;">t</span> = F.relu<span style="color: #8d5649;">(</span><span style="color: #b9ca4a;">self</span>.conv2<span style="color: #d8241f;">(</span>t<span style="color: #d8241f;">)</span><span style="color: #8d5649;">)</span>
    <span style="color: #e7c547;">t</span> = F.max_pool2d<span style="color: #8d5649;">(</span>t, kernel_size=2, stride=2<span style="color: #8d5649;">)</span>

    <span style="color: #e7c547;">t</span> = F.relu<span style="color: #8d5649;">(</span><span style="color: #b9ca4a;">self</span>.fc1<span style="color: #d8241f;">(</span>t.view<span style="color: #9564bf;">(</span>-1, 12 * 4 * 4<span style="color: #9564bf;">)</span><span style="color: #d8241f;">)</span><span style="color: #8d5649;">)</span>
    <span style="color: #e7c547;">t</span> = F.relu<span style="color: #8d5649;">(</span><span style="color: #b9ca4a;">self</span>.fc2<span style="color: #d8241f;">(</span>t<span style="color: #d8241f;">)</span><span style="color: #8d5649;">)</span>
    <span style="color: #e7c547;">t</span> = <span style="color: #b9ca4a;">self</span>.out<span style="color: #8d5649;">(</span>t<span style="color: #8d5649;">)</span>

    <span style="color: #b9ca4a;">return</span> t


<span style="color: #e7c547;">train_set</span> = torchvision.datasets.FashionMNIST<span style="color: #8d5649;">(</span>
  root=<span style="color: #70c0b1;">'./data'</span>,
  train=<span style="color: #7aa6da;">True</span>,
  download=<span style="color: #7aa6da;">True</span>,
  transform=transforms.Compose<span style="color: #d8241f;">(</span><span style="color: #9564bf;">[</span>transforms.ToTensor<span style="color: #24a222;">()</span><span style="color: #9564bf;">]</span><span style="color: #d8241f;">)</span>
<span style="color: #8d5649;">)</span>


<span style="color: #e7c547;">network</span> = Network<span style="color: #8d5649;">()</span>
<span style="color: #e7c547;">sample</span> = <span style="color: #c397d8;">next</span><span style="color: #8d5649;">(</span><span style="color: #c397d8;">iter</span><span style="color: #d8241f;">(</span>train_set<span style="color: #d8241f;">)</span><span style="color: #8d5649;">)</span>
<span style="color: #e7c547;">image</span>, <span style="color: #e7c547;">label</span> = sample

image.unsqueeze<span style="color: #8d5649;">(</span>0<span style="color: #8d5649;">)</span>.shape
<span style="color: #e7c547;">pred</span> = network<span style="color: #8d5649;">(</span>image.unsqueeze<span style="color: #d8241f;">(</span>0<span style="color: #d8241f;">)</span><span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>pred<span style="color: #8d5649;">)</span>
<span style="color: #b9ca4a;">print</span><span style="color: #8d5649;">(</span>pred.argmax<span style="color: #d8241f;">(</span>dim=1<span style="color: #d8241f;">)</span><span style="color: #8d5649;">)</span>
</pre>
</div>

<pre class="example">
tensor([[ 0.0885,  0.1149,  0.0712,  0.0994, -0.0972,  0.0525, -0.0515,  0.0867,  0.1027,  0.0180]], grad_fn=&lt;AddmmBackward&gt;)
tensor([1])

</pre>
</div>
</div>
</div>

<div id="outline-container-orgff233a4" class="outline-2">
<h2 id="orgff233a4"><span class="section-number-2">6</span> 附录</h2>
<div class="outline-text-2" id="text-6">
<p>
安装 PyTorch 之前最好是配合 Anaconda3 发行版一起安装，安装好 Anaconda 过后直接
使用下面命令安装
</p>
<div class="org-src-container">
<pre class="src src-sh">conda install pytorch torchvision -c pytorch
</pre>
</div>

<p>
也可以使用 pip 安装对应的 wheel 包
</p>
<div class="org-src-container">
<pre class="src src-sh">pip3 install torch torchvision
</pre>
</div>
</div>
</div>

<div id="outline-container-orgade9926" class="outline-2">
<h2 id="orgade9926"><span class="section-number-2">7</span> 参考链接</h2>
<div class="outline-text-2" id="text-7">
<ol class="org-ol">
<li><a href="https://pytorch.org/">PyTorch</a></li>
<li><a href="https://pytorch.org/docs/stable/index.html">PyTorch Doc</a></li>
<li><a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/">Anaconda Download</a></li>
<li><a href="https://orgmode.org/worg/org-contrib/babel/languages/ob-doc-python.html">org-mode python</a></li>
</ol>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Last Updated 2020-11-01 Sun 10:50. Created by Jinghui Hu at 2020-10-12 Mon 10:48.</p>
</div>
</body>
</html>
